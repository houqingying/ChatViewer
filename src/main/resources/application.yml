server:
  servlet:
    encoding:
      force: true
      charset: UTF-8
spring:
  servlet:
    multipart:
      # 上传文件允许的最大大小
      max-file-size: 10MB
      max-request-size: 10MB
  application:
    name: ChatViewer
  datasource:
    druid:
      # 数据库连接
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://127.0.0.1:3306/blog?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&useSSL=false&allowPublicKeyRetrieval=true&allowMultiQueries=true
      # ！更改密码
      username: root
      password: 'yourPassword'
  redis:
    host: 127.0.0.1
    port: 6379
    lettuce:
      pool:
        max-active: 10
        max-idle: 10
        min-idle: 1
        time-between-eviction-runs: 10s
    # ！如果你的Redis设置了密码，需要此字段，否则删去即可
    password: yourRedisPassword
  kafka:
    bootstrap-servers: 127.0.0.1:9092 # kafka集群信息，多个用逗号间隔
    # 生产者
    producer:
      # 重试次数，设置大于0的值，则客户端会将发送失败的记录重新发送
      retries: 1
      batch-size: 16384 #批量处理大小，16K
      buffer-memory: 33554432 #缓冲存储大，32M
      acks: 1
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 消费者
    consumer:
      # 消费者组
      group-id: message
      # 是否自动提交
      enable-auto-commit: true
      auto-commit-interval: 3000
      # 消费偏移配置
      # none：如果没有为消费者找到先前的offset的值,即没有自动维护偏移量,也没有手动维护偏移量,则抛出异常
      # earliest：在各分区下有提交的offset时：从offset处开始消费；在各分区下无提交的offset时：从头开始消费
      # latest：在各分区下有提交的offset时：从offset处开始消费；在各分区下无提交的offset时：从最新的数据开始消费
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    # 监听
    listener:
      # record：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # batch：当每一批poll()的数据被ListenerConsumer处理之后提交
      # time：当每一批poll()的数据被ListenerConsumer处理之后，距离上次提交时间大于TIME时提交
      # count：当每一批poll()的数据被ListenerConsumer处理之后，被处理record数量大于等于COUNT时提交
      # count_time：TIME或COUNT中有一个条件满足时提交
      # manual：当每一批poll()的数据被ListenerConsumer处理之后, 手动调用Acknowledgment.acknowledge()后提交
      # manual_immediate：手动调用Acknowledgment.acknowledge()后立即提交，一般推荐使用这种
      ack-mode: record
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  global-config:
    db-config:
      id-type: ASSIGN_ID
mybatis:
  # 设置mapper.xml文件文职
  mapper-locations: classpath:com/chatviewer/blog/mapper/*.xml
my-conf:
  # 第三方服务设置
  gpt-key: GPT的APIKey，从OpenAI官网获取，如sk-xxxxxxxxx
  ali-key: 阿里云的accessKey
  ali-secret: 阿里云的secretKey
  sign-name: 阿里云短信模板名称
  template-code: 阿里云短信模板代码，如SM-xxxxxxxx
  oss-end-point: 阿里云OSS的end-point，如oss-cn-beijing.aliyuncs.com
  oss-bucket:  阿里云OSS的bucket-name，如upload-bucket